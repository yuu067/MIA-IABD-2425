{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuu067/MIA-IABD-2425/blob/main/UD03/notebooks/EX2.5_NLTKyPython.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afcea688-88b6-46ea-a926-e12770c2aaa5",
      "metadata": {
        "id": "afcea688-88b6-46ea-a926-e12770c2aaa5"
      },
      "source": [
        "# Ejercicios UD03_02.5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a2f1713",
      "metadata": {
        "id": "9a2f1713"
      },
      "source": [
        "## Uso de NLTK y Python\n",
        "\n",
        "* *Referencias:*\n",
        "    * *http://www.nltk.org/*\n",
        "    * *http://www.python.org/*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bd2f7bd-9dbf-4e6b-a44c-b28e50be76eb",
      "metadata": {
        "id": "7bd2f7bd-9dbf-4e6b-a44c-b28e50be76eb"
      },
      "source": [
        "### a)Procesamiento del corpus cess_esp anotado con información morfosintáctica.\n",
        "\n",
        "* Dividir el corpus en dos partes: training (el 90% de las primeras frases) y de test (el 10% restante)\n",
        "* Reducir el conjunto de etiquetas morfosintácticas del corpus (289) a un conjunto reducido(67). Para ello, considerar las etiquetas de longitud =2 salvo los verbos (v) y los signos de puntuación (F) que pueden ser de tres. También pueden existir etiquetas de longitud =1. Eliminar también las tuplas vacias, por ejemplo: (u'*0*', u'sn'), son tuplas que el primer elemento tiene el valor '*0*'.\n",
        "\n",
        ">Nota: para entender el significado de las etiquetas se puede consultar el siguiente enlace: https://freeling-user-manual.readthedocs.io/en/latest/tagsets/tagset-es/\n",
        "\n",
        "Ejemplo de lo que se pide:\n",
        "* original\n",
        "```\n",
        "[[('El', 'da0ms0'), ('grupo', 'ncms000'), ('estatal', 'aq0cs0'), ('Electricité_de_France', 'np00000'), ('-Fpa-', 'Fpa'), ('EDF', 'np00000'), ('-Fpt-', 'Fpt'), ('anunció', 'vmis3s0'), ('hoy', 'rg'), (',', 'Fc'), ('jueves', 'W'), (',', 'Fc'), ('la', 'da0fs0'), ('compra', 'ncfs000'), ('del', 'spcms'), ('51_por_ciento', 'Zp'), ('de', 'sps00'), ('la', 'da0fs0'), ('empresa', 'ncfs000'), ('mexicana', 'aq0fs0'), ('Electricidad_Águila_de_Altamira', 'np00000'), ('-Fpa-', 'Fpa'), ('EAA', 'np00000'), ('-Fpt-', 'Fpt'), (',', 'Fc'), ('creada', 'aq0fsp'), ('por', 'sps00'), ('el', 'da0ms0'), ('japonés', 'aq0ms0'), ('Mitsubishi_Corporation', 'np00000'), ('para', 'sps00'), ('poner_en_marcha', 'vmn0000'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('de', 'sps00'), ('495', 'Z'), ('megavatios', 'ncmp000'), ('.', 'Fp')], [('Una', 'di0fs0'), ('portavoz', 'nccs000'), ('de', 'sps00'), ('EDF', 'np00000'), ('explicó', 'vmis3s0'), ('a', 'sps00'), ('EFE', 'np00000'), ('que', 'cs'), ('el', 'da0ms0'), ('proyecto', 'ncms000'), ('para', 'sps00'), ('la', 'da0fs0'), ('construcción', 'ncfs000'), ('de', 'sps00'), ('Altamira_2', 'np00000'), (',', 'Fc'), ('al', 'spcms'), ('norte', 'ncms000'), ('de', 'sps00'), ('Tampico', 'np00000'), (',', 'Fc'), ('prevé', 'vmm02s0'), ('la', 'da0fs0'), ('utilización', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('natural', 'aq0cs0'), ('como', 'cs'), ('combustible', 'ncms000'), ('principal', 'aq0cs0'), ('en', 'sps00'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('ciclo', 'ncms000'), ('combinado', 'aq0msp'), ('que', 'pr0cn000'), ('debe', 'vmip3s0'), ('empezar', 'vmn0000'), ('a', 'sps00'), ('funcionar', 'vmn0000'), ('en', 'sps00'), ('mayo_del_2002', 'W'), ('.', 'Fp')]]\n",
        "```\n",
        "* nuevo\n",
        "```\n",
        "[[('El', 'da'), ('grupo', 'nc'), ('estatal', 'aq'), ('Electricité_de_France', 'np'), ('-Fpa-', 'fpa'), ('EDF', 'np'), ('-Fpt-', 'fpt'), ('anunció', 'vmi'), ('hoy', 'rg'), (',', 'fc'), ('jueves', 'w'), (',', 'fc'), ('la', 'da'), ('compra', 'nc'), ('del', 'sp'), ('51_por_ciento', 'zp'), ('de', 'sp'), ('la', 'da'), ('empresa', 'nc'), ('mexicana', 'aq'), ('Electricidad_Águila_de_Altamira', 'np'), ('-Fpa-', 'fpa'), ('EAA', 'np'), ('-Fpt-', 'fpt'), (',', 'fc'), ('creada', 'aq'), ('por', 'sp'), ('el', 'da'), ('japonés', 'aq'), ('Mitsubishi_Corporation', 'np'), ('para', 'sp'), ('poner_en_marcha', 'vmn'), ('una', 'di'), ('central', 'nc'), ('de', 'sp'), ('gas', 'nc'), ('de', 'sp'), ('495', 'z'), ('megavatios', 'nc'), ('.', 'fp')], [('Una', 'di'), ('portavoz', 'nc'), ('de', 'sp'), ('EDF', 'np'), ('explicó', 'vmi'), ('a', 'sp'), ('EFE', 'np'), ('que', 'cs'), ('el', 'da'), ('proyecto', 'nc'), ('para', 'sp'), ('la', 'da'), ('construcción', 'nc'), ('de', 'sp'), ('Altamira_2', 'np'), (',', 'fc'), ('al', 'sp'), ('norte', 'nc'), ('de', 'sp'), ('Tampico', 'np'), (',', 'fc'), ('prevé', 'vmm'), ('la', 'da'), ('utilización', 'nc'), ('de', 'sp'), ('gas', 'nc'), ('natural', 'aq'), ('como', 'cs'), ('combustible', 'nc'), ('principal', 'aq'), ('en', 'sp'), ('una', 'di'), ('central', 'nc'), ('de', 'sp'), ('ciclo', 'nc'), ('combinado', 'aq'), ('que', 'pr'), ('debe', 'vmi'), ('empezar', 'vmn'), ('a', 'sp'), ('funcionar', 'vmn'), ('en', 'sp'), ('mayo_del_2002', 'w'), ('.', 'fp')]]\n",
        "```\n",
        "* opcional:\n",
        "    * número de frases: 6030\n",
        "    * número de palabras: 192686\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6bf51799-c2de-4f4d-b8bb-95dbd6ea2ebb",
      "metadata": {
        "id": "6bf51799-c2de-4f4d-b8bb-95dbd6ea2ebb"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1958cdd1",
      "metadata": {
        "id": "1958cdd1",
        "outputId": "76a5a6a6-16b9-4d49-b288-95e9d582b5ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> cess_esp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    Downloading package cess_esp to /root/nltk_data...\n",
            "      Unzipping corpora/cess_esp.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#Descargar el corpus\n",
        "#1. ejecutar esta linea\n",
        "nltk.download()\n",
        "#2. elegir la opción d) Download\n",
        "#3. escribir identificador del corpus que deseamos, en nuestro caso 'cess_esp', 'punkt'... o bien 'all'\n",
        "#4. q) quit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fe24a7cb",
      "metadata": {
        "id": "fe24a7cb",
        "outputId": "35088d8c-e94c-4532-b1c9-55ec109a2a3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de sentencias: 6030\n",
            "Total de palabras: 192686\n",
            "Ejemplo de oraciones etiquetadas en el corpus:\n",
            "[[('El', 'da0ms0'), ('grupo', 'ncms000'), ('estatal', 'aq0cs0'), ('Electricité_de_France', 'np00000'), ('-Fpa-', 'Fpa'), ('EDF', 'np00000'), ('-Fpt-', 'Fpt'), ('anunció', 'vmis3s0'), ('hoy', 'rg'), (',', 'Fc'), ('jueves', 'W'), (',', 'Fc'), ('la', 'da0fs0'), ('compra', 'ncfs000'), ('del', 'spcms'), ('51_por_ciento', 'Zp'), ('de', 'sps00'), ('la', 'da0fs0'), ('empresa', 'ncfs000'), ('mexicana', 'aq0fs0'), ('Electricidad_Águila_de_Altamira', 'np00000'), ('-Fpa-', 'Fpa'), ('EAA', 'np00000'), ('-Fpt-', 'Fpt'), (',', 'Fc'), ('creada', 'aq0fsp'), ('por', 'sps00'), ('el', 'da0ms0'), ('japonés', 'aq0ms0'), ('Mitsubishi_Corporation', 'np00000'), ('para', 'sps00'), ('poner_en_marcha', 'vmn0000'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('de', 'sps00'), ('495', 'Z'), ('megavatios', 'ncmp000'), ('.', 'Fp')], [('Una', 'di0fs0'), ('portavoz', 'nccs000'), ('de', 'sps00'), ('EDF', 'np00000'), ('explicó', 'vmis3s0'), ('a', 'sps00'), ('EFE', 'np00000'), ('que', 'cs'), ('el', 'da0ms0'), ('proyecto', 'ncms000'), ('para', 'sps00'), ('la', 'da0fs0'), ('construcción', 'ncfs000'), ('de', 'sps00'), ('Altamira_2', 'np00000'), (',', 'Fc'), ('al', 'spcms'), ('norte', 'ncms000'), ('de', 'sps00'), ('Tampico', 'np00000'), (',', 'Fc'), ('prevé', 'vmm02s0'), ('la', 'da0fs0'), ('utilización', 'ncfs000'), ('de', 'sps00'), ('gas', 'ncms000'), ('natural', 'aq0cs0'), ('como', 'cs'), ('combustible', 'ncms000'), ('principal', 'aq0cs0'), ('en', 'sps00'), ('una', 'di0fs0'), ('central', 'ncfs000'), ('de', 'sps00'), ('ciclo', 'ncms000'), ('combinado', 'aq0msp'), ('que', 'pr0cn000'), ('debe', 'vmip3s0'), ('empezar', 'vmn0000'), ('a', 'sps00'), ('funcionar', 'vmn0000'), ('en', 'sps00'), ('mayo_del_2002', 'W'), ('.', 'Fp')]]\n",
            "[[('El', 'da'), ('grupo', 'nc'), ('estatal', 'aq'), ('Electricité_de_France', 'np'), ('-Fpa-', 'Fpa'), ('EDF', 'np'), ('-Fpt-', 'Fpt'), ('anunció', 'vm'), ('hoy', 'rg'), (',', 'Fc'), ('jueves', 'W'), (',', 'Fc'), ('la', 'da'), ('compra', 'nc'), ('del', 'sp'), ('51_por_ciento', 'Zp'), ('de', 'sp'), ('la', 'da'), ('empresa', 'nc'), ('mexicana', 'aq'), ('Electricidad_Águila_de_Altamira', 'np'), ('-Fpa-', 'Fpa'), ('EAA', 'np'), ('-Fpt-', 'Fpt'), (',', 'Fc'), ('creada', 'aq'), ('por', 'sp'), ('el', 'da'), ('japonés', 'aq'), ('Mitsubishi_Corporation', 'np'), ('para', 'sp'), ('poner_en_marcha', 'vm'), ('una', 'di'), ('central', 'nc'), ('de', 'sp'), ('gas', 'nc'), ('de', 'sp'), ('495', 'Z'), ('megavatios', 'nc'), ('.', 'Fp')], [('Una', 'di'), ('portavoz', 'nc'), ('de', 'sp'), ('EDF', 'np'), ('explicó', 'vm'), ('a', 'sp'), ('EFE', 'np'), ('que', 'cs'), ('el', 'da'), ('proyecto', 'nc'), ('para', 'sp'), ('la', 'da'), ('construcción', 'nc'), ('de', 'sp'), ('Altamira_2', 'np'), (',', 'Fc'), ('al', 'sp'), ('norte', 'nc'), ('de', 'sp'), ('Tampico', 'np'), (',', 'Fc'), ('prevé', 'vm'), ('la', 'da'), ('utilización', 'nc'), ('de', 'sp'), ('gas', 'nc'), ('natural', 'aq'), ('como', 'cs'), ('combustible', 'nc'), ('principal', 'aq'), ('en', 'sp'), ('una', 'di'), ('central', 'nc'), ('de', 'sp'), ('ciclo', 'nc'), ('combinado', 'aq'), ('que', 'pr'), ('debe', 'vm'), ('empezar', 'vm'), ('a', 'sp'), ('funcionar', 'vm'), ('en', 'sp'), ('mayo_del_2002', 'W'), ('.', 'Fp')], [('La', 'da'), ('electricidad', 'nc'), ('producida', 'aq'), ('pasará', 'vm'), ('a', 'sp'), ('la', 'da'), ('red', 'nc'), ('eléctrica', 'aq'), ('pública', 'aq'), ('de', 'sp'), ('México', 'np'), ('en_virtud_de', 'sp'), ('un', 'di'), ('acuerdo', 'nc'), ('de', 'sp'), ('venta', 'nc'), ('de', 'sp'), ('energía', 'nc'), ('de', 'sp'), ('EAA', 'np'), ('con', 'sp'), ('la', 'da'), ('Comisión_Federal_de_Electricidad', 'np'), ('-Fpa-', 'Fpa'), ('CFE', 'np'), ('-Fpt-', 'Fpt'), ('por', 'sp'), ('una', 'di'), ('duración', 'nc'), ('de', 'sp'), ('25', 'Z'), ('años', 'nc'), ('.', 'Fp')]]\n"
          ]
        }
      ],
      "source": [
        "#Esta linea carga el corpus en castellano, pero podemos hacerlo en ingles o catalan si os apetece\n",
        "from nltk.corpus import cess_esp\n",
        "corpus_sentences=cess_esp.tagged_sents()\n",
        "\n",
        "# Opcional: mostramos el número de sentencias y palabras\n",
        "total_sentences = len(corpus_sentences)\n",
        "total_words = sum(len(sentence) for sentence in corpus_sentences)\n",
        "print(f\"Total de sentencias: {total_sentences}\")\n",
        "print(f\"Total de palabras: {total_words}\")\n",
        "\n",
        "# Mostrar las 3 primeras frases del corpus\n",
        "print(\"Ejemplo de oraciones etiquetadas en el corpus:\")\n",
        "print(corpus_sentences[:2])\n",
        "\n",
        "#Escribir el corpus en un fichero\n",
        "with open('corpus_sentences.txt', 'w', encoding='utf-8') as file:\n",
        "    for sentence in corpus_sentences:\n",
        "        for word, tag in sentence:\n",
        "            file.write(f\"{word}\\t{tag}\\n\")\n",
        "\n",
        "#Leer el corpus de un fichero y guardalo en una lista\n",
        "corpus_sentences = []\n",
        "with open('corpus_sentences.txt', 'r', encoding='utf-8') as file:\n",
        "    sentence = []\n",
        "    for line in file:\n",
        "        word, tag = line.strip().split('\\t')\n",
        "        sentence.append((word, tag))\n",
        "        if word == '.':\n",
        "            corpus_sentences.append(sentence)\n",
        "            sentence = []\n",
        "\n",
        "#Definimos una funcion auxiliar (getLabel) que a partir de una etiqueta, la reduzca a su nueva versión siguiendo las instrucciones del enunciado\n",
        "def getLabel(tag):\n",
        "    if tag.startswith('V') or tag.startswith('F') and len(tag) == 3:\n",
        "        return tag[:3]\n",
        "    return tag[:2] if len(tag) > 1 else tag\n",
        "\n",
        "#Definimos un array retic. A continuación leeremos todo el corpus, para cada etiqueta la procesaremos con getLabel y la guardaremos en retic.\n",
        "retic = []\n",
        "for sentence in corpus_sentences:\n",
        "    new_sentence = [(word, getLabel(tag)) for word, tag in sentence]  # Apply getLabel to each tag within the sentence\n",
        "    retic.append(new_sentence)\n",
        "\n",
        "#mostramos las 3 primeras frases del corpus con las etiquetas reducidas (como muestra el enunciado)\n",
        "print(retic[0:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35dee72f",
      "metadata": {
        "id": "35dee72f"
      },
      "source": [
        "### b) Uso de etiquetadores morfosintácticos (hmm o tnt).\n",
        "* Entrenar los etiquetadores con la partición de train previamente construida mostrar la precisión:\n",
        "\n",
        "```\n",
        "precisión hmm: 0.8784427571832664\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5faa3b76",
      "metadata": {
        "id": "5faa3b76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b503144-eca1-4aa7-c616-840397c7bb05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-97dc91d048c2>:12: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  hmm_accuracy = hmm_tagger.evaluate(test_corpus)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión hmm: 0.8938413948256468\n"
          ]
        }
      ],
      "source": [
        "from nltk.tag import HiddenMarkovModelTagger\n",
        "\n",
        "# Define train and test sets using the updated corpus\n",
        "train_size = int(len(retic) * 0.9)\n",
        "train_corpus = retic[:train_size]\n",
        "test_corpus = retic[train_size:]\n",
        "\n",
        "# Train the HMM tagger\n",
        "hmm_tagger = HiddenMarkovModelTagger.train(train_corpus)\n",
        "\n",
        "# Evaluate the tagger\n",
        "hmm_accuracy = hmm_tagger.evaluate(test_corpus)\n",
        "print(f\"Precisión hmm: {hmm_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4bae1bb",
      "metadata": {
        "id": "f4bae1bb"
      },
      "source": [
        "### c) Etiquetar con dicho modelo el conjunto de test construido\n",
        "* Evaluar las prestaciones sobre el conjunto de test\n",
        "* Hacer una evaluación de las prestaciones de etiquetado usando todo el corpus (10-fold cross validation).\n",
        "\n",
        "```\n",
        "Media de la precisión de los 10 KFolds:  0.9580362988365326\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3a63aade-6345-48f4-b559-d78f275ee306",
      "metadata": {
        "id": "3a63aade-6345-48f4-b559-d78f275ee306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f0a88489-1f92-4c8f-94ee-c4b2f66a4882"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.6.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#importamos scikit-learn y mostramos la versión para comprobar que todo funcione bien.\n",
        "import sklearn\n",
        "sklearn.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1be17685-3072-4bc9-821d-0115b69f9713",
      "metadata": {
        "scrolled": true,
        "id": "1be17685-3072-4bc9-821d-0115b69f9713",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "565634d5-4ab4-4c6e-96df-a563207af0d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-c27aab3292d7>:10: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  accuracy = hmm_tagger.evaluate(test_data)\n"
          ]
        }
      ],
      "source": [
        "#Montamos el kfold de 10 splits sin shuffle y sin random_state\n",
        "#Para cada KFold guardamos su accuracy, y finalmente mostramos la media de los 10.\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=10, shuffle=False)\n",
        "accuracies = []\n",
        "for train_index, test_index in kf.split(retic):\n",
        "    train_data = [retic[i] for i in train_index]\n",
        "    test_data = [retic[i] for i in test_index]\n",
        "    hmm_tagger = HiddenMarkovModelTagger.train(train_data)\n",
        "    accuracy = hmm_tagger.evaluate(test_data)\n",
        "    accuracies.append(accuracy)\n",
        "average_accuracy = sum(accuracies) / len(accuracies)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_accuracy"
      ],
      "metadata": {
        "id": "YxwQ9iBMWUg8",
        "outputId": "774dc758-7a5b-4e9d-e0df-970516f7f932",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "YxwQ9iBMWUg8",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.911453752216071"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93b6532c-73f5-4e76-94cd-009a8f52fde0",
      "metadata": {
        "id": "93b6532c-73f5-4e76-94cd-009a8f52fde0"
      },
      "source": [
        "### d) Tokenizar una frase y etiquetarla con el modelo entrenado previamente\n",
        "* Usar word_tokenize y tag del modelo usado (tnt, hmm)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "YwXa0AVvVwO7",
        "outputId": "790a0f12-f4ec-4de4-812e-1c20631e01cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "YwXa0AVvVwO7",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# New sentence to tokenize and tag\n",
        "new_sentence = \"El presidente anunció hoy un nuevo plan económico para el país durante su visita a Barcelona.\"\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokens = word_tokenize(new_sentence)\n",
        "print(\"Tokens:\", tokens)\n",
        "\n",
        "# Use the trained HMM tagger to tag the tokens\n",
        "# We'll use the model trained on the entire training set from part b\n",
        "tagged_sentence = hmm_tagger.tag(tokens)\n",
        "print(\"Tagged sentence:\")\n",
        "for word, tag in tagged_sentence:\n",
        "    print(f\"{word}: {tag}\")"
      ],
      "metadata": {
        "id": "KY39WlJuWmeU",
        "outputId": "f6421315-1f79-4722-c85e-89afe5c0cc18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "KY39WlJuWmeU",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['El', 'presidente', 'anunció', 'hoy', 'un', 'nuevo', 'plan', 'económico', 'para', 'el', 'país', 'durante', 'su', 'visita', 'a', 'Barcelona', '.']\n",
            "Tagged sentence:\n",
            "El: da\n",
            "presidente: nc\n",
            "anunció: vm\n",
            "hoy: rg\n",
            "un: di\n",
            "nuevo: aq\n",
            "plan: nc\n",
            "económico: aq\n",
            "para: sp\n",
            "el: da\n",
            "país: nc\n",
            "durante: sp\n",
            "su: dp\n",
            "visita: nc\n",
            "a: sp\n",
            "Barcelona: np\n",
            ".: Fp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44b71a91-6d42-4673-ba93-face2dddef5a",
      "metadata": {
        "id": "44b71a91-6d42-4673-ba93-face2dddef5a"
      },
      "source": [
        "### e) De manera opcional puedes probar a cambiar el idioma, el corpus y ver si afecta mucho a la precisión de los modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fd6a8eb-9c0d-4f65-a173-ee5a78108ec3",
      "metadata": {
        "id": "4fd6a8eb-9c0d-4f65-a173-ee5a78108ec3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b7da9344-3aaa-4c68-bad1-22dad8a56974",
      "metadata": {
        "id": "b7da9344-3aaa-4c68-bad1-22dad8a56974"
      },
      "source": [
        "### f) Entrega este notebook completado (asegurate que funciona correctamente, y renombralo añadiendo tu nombre y apellidos al final) en la tarea de AULES de la unidad 3."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}